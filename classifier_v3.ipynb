{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chord classifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Xt-8qB58u2_y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Packages installation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "SsWRTAQULONO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
    "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local"
   ],
   "metadata": {
    "id": "2SS7bMiAyRSX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
   ],
   "metadata": {
    "id": "8rhj8TkuyXRz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!conda install -c conda-forge ffmpeg libsndfile"
   ],
   "metadata": {
    "id": "SkbLGjSLu2_0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install spleeter"
   ],
   "metadata": {
    "id": "3v-Uf9rZu2_1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%pip install pandas numpy librosa matplotlib torch torchvision seaborn"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-QVyZk6y0nc_",
    "outputId": "593384ad-9eb1-458a-cd8f-ff024a684f26"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%pip install \"ray[tune]\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mb4P8XkEnmq7",
    "outputId": "7bab0582-bc94-42d5-e653-5f3bc00bc3aa"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting ray[tune]\n",
      "  Downloading ray-2.9.2-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.9/64.9 MB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.19.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.0.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.31.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.5.3)\n",
      "Collecting tensorboardX>=1.9 (from ray[tune])\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.7/101.7 kB\u001B[0m \u001B[31m13.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (10.0.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2023.6.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow>=6.0.1->ray[tune]) (1.23.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ray[tune]) (1.16.0)\n",
      "Installing collected packages: tensorboardX, ray\n",
      "Successfully installed ray-2.9.2 tensorboardX-2.6.2.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import ray"
   ],
   "metadata": {
    "id": "6s463FSjZsGx"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "id": "rmWFaHtPLONQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of preprocessing step, which is crucial for training the model, is to convert each chord represented as `wav` file into   spectrograms.\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "uMqj0zz2u2_1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "id": "OUhOhQU6u2_1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Google Colab file management (no need to run outside Colab)"
   ],
   "metadata": {
    "collapsed": false,
    "id": "qVBE4Vj_LONR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For usage of data in Google Colab, I mount my Google Drive and then copy files from it to the local instance to make processing faster."
   ],
   "metadata": {
    "collapsed": false,
    "id": "OPD9C4CRu2_1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0foJ3AMw0tN",
    "outputId": "eef056f7-ebe2-4d15-9ace-b50bfc05a070"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /gdrive\n",
      "/gdrive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "os.chdir(\"/content\")"
   ],
   "metadata": {
    "id": "EZFpDsTJxRpS"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!cp -R \"/gdrive/My Drive/chord_classifier/data\" \"data\""
   ],
   "metadata": {
    "id": "z8E-C9mMpUXe"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data exploration\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "yGM2NlCju2_2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "data_dir = \"data\"\n",
    "preprocessed_train_data_dir = Path(os.path.join(data_dir, \"preprocessed\", \"train\"))\n",
    "preprocessed_test_data_dir = Path(os.path.join(data_dir, \"preprocessed\", \"test\"))\n",
    "pretrained_models_dir = Path(\"pretrained_models\")\n",
    "preprocessed_train_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "preprocessed_test_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "pretrained_models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_data_dir = data_dir + \"/Training\"\n",
    "test_data_dir = data_dir + \"/Test\""
   ],
   "metadata": {
    "id": "MaJyzqRzLONS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show the number of chord recordings available for training and testing"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ASY83Mqqu2_2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_chord_counts(data_dir):\n",
    "    chord_counts = {}\n",
    "\n",
    "    for chord in os.listdir(data_dir):\n",
    "        chord_path = os.path.join(data_dir, chord)\n",
    "        if os.path.isdir(chord_path):\n",
    "            chord_counts[chord] = len(os.listdir(chord_path))\n",
    "\n",
    "    return chord_counts"
   ],
   "metadata": {
    "id": "9vEb-JWvu2_2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Training data chord count {get_chord_counts(train_data_dir)}\")\n",
    "print(f\"Testing data chord count {get_chord_counts(test_data_dir)}\")"
   ],
   "metadata": {
    "id": "imX0urefu2_2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show the duration of sounds of chords. It ranges from 1.12 to 16.34 seconds with median about 5 seconds."
   ],
   "metadata": {
    "collapsed": false,
    "id": "Xm-YKrM1u2_3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "durations = []\n",
    "\n",
    "for chord in os.listdir(train_data_dir):\n",
    "    chord_path = os.path.join(train_data_dir, chord)\n",
    "    if os.path.isdir(chord_path):\n",
    "        for file in os.listdir(chord_path):\n",
    "            file_path = os.path.join(chord_path, file)\n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "            durations.append(librosa.get_duration(y=y, sr=sr))\n",
    "\n",
    "durations_df = pd.DataFrame(durations, columns=['duration'])\n",
    "durations_df.describe()"
   ],
   "metadata": {
    "id": "PWs-EDGCu2_3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A little trick to create an image from a spectrogram with matplotlib and then save it."
   ],
   "metadata": {
    "collapsed": false,
    "id": "pWGyYICru2_3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_spectrogram(audio_input, sr=None, save_path=None):\n",
    "    # skip already existing sprectrogram\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Spectrogram  {save_path} already exists. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Load the audio file if a path is provided, else use the provided audio data\n",
    "    if isinstance(audio_input, str):\n",
    "        y, sr = librosa.load(audio_input, sr=None)\n",
    "    else:\n",
    "        y = audio_input\n",
    "        if sr is None:\n",
    "            raise ValueError(\"Sampling rate must be provided with audio data\")\n",
    "\n",
    "    print(f\"Creating spectrogram {save_path}\")\n",
    "\n",
    "    # Generate the Mel spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Plot and save the spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.axis('off')\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0, format=\"jpg\")\n",
    "    plt.close()\n",
    "\n",
    "    return S_dB\n"
   ],
   "metadata": {
    "id": "OcNPyjwhu2_3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_chords_to_spectrograms(source_dir, destination_dir, durations=[0.4, 0.5, 0.6]):\n",
    "    for chord in os.listdir(source_dir):\n",
    "        chord_path = os.path.join(source_dir, chord)\n",
    "        preprocessed_chord_path = os.path.join(destination_dir, chord)\n",
    "\n",
    "        if not os.path.exists(preprocessed_chord_path):\n",
    "            os.makedirs(preprocessed_chord_path)\n",
    "\n",
    "        if os.path.isdir(chord_path):\n",
    "            for file in os.listdir(chord_path):\n",
    "                file_path = os.path.join(chord_path, file)\n",
    "                y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                for beat_duration in durations:\n",
    "                    samples_per_beat = int(beat_duration * sr)\n",
    "\n",
    "                    for i in range(0, len(y), samples_per_beat):\n",
    "                        end_frame = i + samples_per_beat\n",
    "                        if end_frame > len(y):\n",
    "                            end_frame = len(y)  # Adjust the end frame for the last segment\n",
    "\n",
    "                        segment = y[i:end_frame]\n",
    "                        duration_ms = int(beat_duration * 1000)  # Convert to milliseconds for filename\n",
    "                        save_path = os.path.join(preprocessed_chord_path, f\"{os.path.splitext(file)[0]}_{i // samples_per_beat}_{duration_ms}ms.jpg\")\n",
    "                        # Create spectrogram from a segment and save it to disk\n",
    "                        create_spectrogram(segment, sr, save_path)\n",
    "\n"
   ],
   "metadata": {
    "id": "Xa6Jel3ru2_3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert train and test data. This is going to take a while.\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "_oMlp5eSu2_3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "convert_chords_to_spectrograms(train_data_dir, preprocessed_train_data_dir)\n",
    "convert_chords_to_spectrograms(test_data_dir, preprocessed_test_data_dir)"
   ],
   "metadata": {
    "id": "oakTOTEiu2_4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check the number of generated files."
   ],
   "metadata": {
    "collapsed": false,
    "id": "FnAdETfyu2_4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data chord count {'C': 6555, 'G': 6615, 'Am': 6558, 'Em': 6647, 'Bb': 6535, 'Dm': 6515, 'F': 6416}\n",
      "Testing data chord count {}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data chord count {get_chord_counts(preprocessed_train_data_dir)}\")\n",
    "print(f\"Testing data chord count {get_chord_counts(preprocessed_test_data_dir)}\")"
   ],
   "metadata": {
    "id": "O9NI_yORu2_4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ba542f7a-74da-4caf-89a5-4fa78abec5ac"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An example of a spectrogram"
   ],
   "metadata": {
    "collapsed": false,
    "id": "lkzRMMoXu2_4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "image_path = os.path.join(preprocessed_train_data_dir, 'Am', 'Am_acousticguitar_Mari_1_0.jpg')\n",
    "\n",
    "img = mpimg.imread(image_path)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "rT2SeEOTu2_4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine tuning ResNet50\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "epSQxduXu3AF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the model and enable the last layer for fine tuning. If we have a saved version of the model, we can load its state."
   ],
   "metadata": {
    "collapsed": false,
    "id": "Q4KREqLGu3AF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "# use GPU where available\n",
    "device = \"mps\" if getattr(torch, 'has_mps', False) \\\n",
    "    else \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKk_OzWWLONW",
    "outputId": "d23ea8de-75b6-4839-f20f-646ea619ca1d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "def load_model(saved_model_path=None):\n",
    "  num_classes = 7 # we have 7 chords in our dataset\n",
    "  model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "  # replacing the last layer for fine tuning\n",
    "  num_features = model.fc.in_features\n",
    "  model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "\n",
    "  if saved_model_path:\n",
    "    model.load_state_dict(torch.load(saved_model_path, map_location=torch.device(device)))\n",
    "\n",
    "  return model.to(device)\n"
   ],
   "metadata": {
    "id": "j5nQPcFiu3AF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = load_model()"
   ],
   "metadata": {
    "id": "YLLN_7Mz7t8N"
   },
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[10], line 5\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(saved_model_path)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(saved_model_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m      4\u001B[0m   num_classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m7\u001B[39m \u001B[38;5;66;03m# we have 7 chords in our dataset\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m   model \u001B[38;5;241m=\u001B[39m \u001B[43mmodels\u001B[49m\u001B[38;5;241m.\u001B[39mresnet50(weights\u001B[38;5;241m=\u001B[39mResNet50_Weights\u001B[38;5;241m.\u001B[39mDEFAULT)\n\u001B[1;32m      7\u001B[0m   \u001B[38;5;66;03m# replacing the last layer for fine tuning\u001B[39;00m\n\u001B[1;32m      8\u001B[0m   num_features \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfc\u001B[38;5;241m.\u001B[39min_features\n",
      "\u001B[0;31mNameError\u001B[0m: name 'models' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Categorical mapping of chords so that we could use them as numerical indexes in the neural network but also could decipher it back to actual labels for representation."
   ],
   "metadata": {
    "id": "PhvMWvY-75Vf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "chord_labels = [\"Am\", \"Bb\", \"C\", \"Dm\", \"Em\", \"F\", \"G\"]\n",
    "label_to_idx = {\n",
    "    \"Am\": 0,\n",
    "    \"Bb\": 1,\n",
    "    \"C\": 2,\n",
    "    \"Dm\": 3,\n",
    "    \"Em\": 4,\n",
    "    \"F\": 5,\n",
    "    \"G\": 6,\n",
    "}"
   ],
   "metadata": {
    "id": "yEBSo6Tl8CHp"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define our dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "XWwNPmQVu3AF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, include_labels=True, image_mode=\"RGB\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the subdirectories for each label.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.include_labels = include_labels\n",
    "        self.image_mode = image_mode\n",
    "\n",
    "        # Iterate over each subdirectory in root_dir\n",
    "        for label_dir in os.listdir(root_dir):\n",
    "            label_dir_full_path = os.path.join(root_dir, label_dir)\n",
    "            if os.path.isdir(label_dir_full_path):\n",
    "\n",
    "                # Iterate over each file in the subdirectory\n",
    "                for file in os.listdir(label_dir_full_path):\n",
    "                    file_full_path = os.path.join(label_dir_full_path, file)\n",
    "                    if os.path.isfile(file_full_path):\n",
    "                        # Append the file path and its label to the samples list\n",
    "                        self.samples.append((file_full_path, self.label_to_idx[label_dir]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label_idx = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(self.image_mode)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.include_labels:\n",
    "            return img, label_idx\n",
    "\n",
    "        return img\n"
   ],
   "metadata": {
    "id": "Eio5-74xu3AF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function to resize the images to the size expected by ResNet (224x224). As the original images are not square, it also pads them with blank space to keep the proportions as they are crucial for a time representation like the spectrogram."
   ],
   "metadata": {
    "collapsed": false,
    "id": "70rxfFMbu3AG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "def resize_and_pad(spectrogram, target_size=(224, 224)):\n",
    "    # Calculate the resize ratio and resize the spectrogram\n",
    "    ratio = min(target_size[0] / spectrogram.width, target_size[1] / spectrogram.height)\n",
    "    new_size = (int(spectrogram.width * ratio), int(spectrogram.height * ratio))\n",
    "    spectrogram = spectrogram.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "    # Calculate padding\n",
    "    delta_width = target_size[0] - new_size[0]\n",
    "    delta_height = target_size[1] - new_size[1]\n",
    "    padding = (delta_width // 2, delta_height // 2, delta_width - (delta_width // 2), delta_height - (delta_height // 2))\n",
    "\n",
    "    # Add padding\n",
    "    return ImageOps.expand(spectrogram, padding)\n"
   ],
   "metadata": {
    "id": "U_ikXvRGu3AG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A function to calculate mean and standard deviation for normalization.\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "odH3Zu_7u3AG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "def calculate_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        channels = images.size(1)\n",
    "        images = images.view(batch_samples, channels, -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += batch_samples\n",
    "\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "\n",
    "    return mean, std\n"
   ],
   "metadata": {
    "id": "aTK5WfyPu3AG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform the data to the input format expected by the network. This step without the normalization as we first need to calculate the mean and standard deviation.\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "9COMnosNu3AG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "pre_transform = transforms.Compose([\n",
    "    transforms.Lambda(resize_and_pad),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ],
   "metadata": {
    "id": "UBqZ21SIu3AG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following operation is to calculate mean and std across the training dataset for normalization. It is an expensive operation so this cell is disabled and the following cell contains those values received from a previous calculation."
   ],
   "metadata": {
    "collapsed": false,
    "id": "b31QXH_pu3AG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "#| code: true\n",
    "#| output: false\n",
    "#} eval: false\n",
    "\n",
    "pre_dataset = SpectrogramDataset(root_dir=preprocessed_train_data_dir, transform=pre_transform)\n",
    "\n",
    "pre_loader = DataLoader(pre_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "mean, std = calculate_mean_std(pre_loader)\n",
    "print(mean, std)\n"
   ],
   "metadata": {
    "id": "bQSBsSiHu3AG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "mean = [0.1940, 0.0823, 0.1370]\n",
    "std = [0.3135, 0.1575, 0.1981]"
   ],
   "metadata": {
    "id": "nPUjEcUau3AH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have all necessary information, we can fully transform the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "id": "YRypMVXsu3AH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(resize_and_pad),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])"
   ],
   "metadata": {
    "id": "-UqW_-uPu3AH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "45831"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = SpectrogramDataset(root_dir=preprocessed_train_data_dir, transform=transform)\n",
    "len(dataset)"
   ],
   "metadata": {
    "id": "XAN024Amu3AH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5411417a-85f9-47a9-9287-67585b4cacac"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create validation dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "4nVG82ycu3AH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "9167"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, validation_dataset = random_split(dataset, [train_size, val_size])\n",
    "len(validation_dataset)"
   ],
   "metadata": {
    "id": "R_6E-KsTu3AH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a3d527bd-8c6a-4cc6-c638-b1428682a488"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function is used for testing the model and returns current loss and accuracy. It is used both for hyperparameter tuning feedback and for testing the model on the test dataset."
   ],
   "metadata": {
    "collapsed": false,
    "id": "20YYxD0vu3AI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "id": "m2Pjyf3du3AI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ],
   "metadata": {
    "id": "xUxWMTtTu3AK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "max_epochs = 30"
   ],
   "metadata": {
    "id": "dPKG7Ogfu3AI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model training loop. It uses checkpoints as the training is a long operation that might be interrupted and it that case we should be able to continue where we left off. It also leverages learning rate scheduler to adjust learning rate during the training to improve convergency."
   ],
   "metadata": {
    "id": "kHQa9MBi9K0f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from ray import train\n",
    "import tempfile\n",
    "from ray.train import Checkpoint\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "\n",
    "checkpoint_dir = os.path.join(pretrained_models_dir, \"checkpoints\")\n",
    "\n",
    "def train_model(config):\n",
    "    # optimizer = getattr(torch.optim, config[\"optimizer\"])(model.parameters(), lr=config[\"lr\"])\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    start = 1\n",
    "    checkpoint = train.get_checkpoint()\n",
    "    if checkpoint:\n",
    "        checkpoint = torch.load(os.path.join(checkpoint_dir, \"checkpoint.pt\"))\n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(validation_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    num_epochs = config.get(\"epochs\", 7)\n",
    "\n",
    "    for epoch in range(start, num_epochs):\n",
    "      print(f\"Start epoch {epoch}\")\n",
    "      model.train()\n",
    "      running_loss = 0.0\n",
    "      for inputs, labels in train_loader:\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      # validation\n",
    "      val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
    "      print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "      scheduler.step()\n",
    "\n",
    "      torch.save({\n",
    "          'epoch': epoch,\n",
    "          'model_state': model.state_dict(),\n",
    "          'optimizer_state': optimizer.state_dict(),\n",
    "          'scheduler_state': scheduler.state_dict(),\n",
    "        }, os.path.join(checkpoint_dir, \"checkpoint.pt\"))\n",
    "\n",
    "      checkpoint=Checkpoint.from_directory(checkpoint_dir)\n",
    "      # send data to Ray Tune at each epoch to allow the scheduler to cancel inefficient experiments early\n",
    "      train.report({\"val_loss\": val_loss, \"accuracy\": val_accuracy})\n"
   ],
   "metadata": {
    "id": "sBRUqnQWu3AI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false,
    "id": "PTVE-XPRu3AI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I use a Ray Tune scheduler to be able to cut off inefficient experiments early and improve the efficiency of hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false,
    "id": "qRcjYnyiu3AJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    max_t = max_epochs,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2,\n",
    ")\n"
   ],
   "metadata": {
    "id": "jslQRUXxu3AJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are hyperparameters that we are going to choose."
   ],
   "metadata": {
    "id": "1OFK0lfb9hl-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "config = {\n",
    "    \"lr\": 0.0151688,\n",
    "    # \"lr\": tune.loguniform(1e-2, 1e-1),\n",
    "    # \"batch_size\": tune.choice([16, 32, 64]),\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": tune.choice([7, 10, 15, 18, 23, 30]),\n",
    "    # \"optimizer\": tune.choice([\"Adam\", \"SGD\"]),\n",
    "    \"step_size\": tune.choice([5, 10, 20]),\n",
    "    \"gamma\": tune.choice([0.1, 0.5, 0.9]),\n",
    "    \"momentum\": tune.uniform(0.8, 0.99),\n",
    "}"
   ],
   "metadata": {
    "id": "QKou6L0Au3AJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2024-02-06 17:05:24,497\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.10.12', ray_version='2.9.2', ray_commit='fce7a361807580953364e2da964f9498f3123bf9', protocol_version=None)"
      ],
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.10.12</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.9.2</b></td>\n",
       "    </tr>\n",
       "    \n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True, local_mode=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "II7CAXI-u3AJ",
    "outputId": "abd1d20f-be1d-4cbe-a0cc-a67d935eb4f1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def get_best_params(config, train_model, scheduler, num_samples=10):\n",
    "    analysis = tune.run(\n",
    "        train_model,\n",
    "        config=config,\n",
    "        num_samples=num_samples,  # Number of times to sample from the hyperparameter space\n",
    "        resources_per_trial={\"cpu\": 8},  # Resources per trial\n",
    "        scheduler=scheduler,\n",
    "        resume=\"AUTO\"\n",
    "    )\n",
    "\n",
    "    return analysis.get_best_config(metric=\"accuracy\", mode=\"max\")"
   ],
   "metadata": {
    "id": "aC58WU_xu3AJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# this is the most successful config received by running hyperparameter tuning on Google Colab\n",
    "best_config = {'lr': 0.0151688, 'batch_size': 16, 'epochs': 15, 'step_size': 20, 'gamma': 0.9, 'momentum': 0.8621876688576123}"
   ],
   "metadata": {
    "id": "UTR93zqGu3AJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run this cell to get current best config result"
   ],
   "metadata": {
    "collapsed": false,
    "id": "pun9Dy_BLONb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2024-02-06 11:08:38,622\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 2. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2024-02-06 11:08:39,573\tINFO experiment_state.py:402 -- No local checkpoint was found. Starting a new run...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------------------------------------------------------+\n",
      "| Configuration for experiment     train_model_2024-02-06_11-08-39   |\n",
      "+--------------------------------------------------------------------+\n",
      "| Search algorithm                 BasicVariantGenerator             |\n",
      "| Scheduler                        AsyncHyperBandScheduler           |\n",
      "| Number of trials                 15                                |\n",
      "+--------------------------------------------------------------------+\n",
      "\n",
      "View detailed results here: /root/ray_results/train_model_2024-02-06_11-08-39\n",
      "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/train_model_2024-02-06_11-08-39`\n",
      ":task_name:bundle_reservation_check_func\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ":task_name:bundle_reservation_check_func\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ":actor_name:ImplicitFunc\n",
      ":actor_name:train_model\n",
      "\n",
      "Trial train_model_14cbf_00000 started with configuration:\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00000 config             |\n",
      "+--------------------------------------------------+\n",
      "| batch_size                                    16 |\n",
      "| epochs                                        10 |\n",
      "| gamma                                        0.9 |\n",
      "| lr                                       0.01517 |\n",
      "| momentum                                 0.98965 |\n",
      "| step_size                                     10 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ":actor_name:ImplicitFunc\n",
      ":actor_name:train_model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3/7, Loss: 0.22839996854680028\n",
      "Save to checkpoint /tmp/tmplghd1973/checkpoint.pt\n",
      "\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2024-02-06 11:22:39. Total running time: 13min 59s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+------------------------------------------------------------------------------------+\n",
      "| Trial name                status       epochs     step_size     gamma     momentum |\n",
      "+------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00000   RUNNING          10            10       0.9     0.989646 |\n",
      "+------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00000 finished iteration 1 at 2024-02-06 11:22:39. Total running time: 13min 59s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00000 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         831.859 |\n",
      "| time_total_s                             831.859 |\n",
      "| training_iteration                             1 |\n",
      "| accuracy                                 0.92431 |\n",
      "| val_loss                                 0.18869 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 3\n",
      "Epoch 2/10, Loss: 0.7285333778367851\n",
      "Save to checkpoint /tmp/tmpgpiu750c/checkpoint.pt\n",
      "\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2024-02-06 11:24:16. Total running time: 15min 36s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status       epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00000   RUNNING          10            10       0.9     0.989646        1            831.859     0.188688      0.92431 |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00000 finished iteration 2 at 2024-02-06 11:24:16. Total running time: 15min 36s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00000 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         96.9096 |\n",
      "| time_total_s                             928.769 |\n",
      "| training_iteration                             2 |\n",
      "| accuracy                                 0.87011 |\n",
      "| val_loss                                 0.35762 |\n",
      "+--------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00000 completed after 2 iterations at 2024-02-06 11:24:16. Total running time: 15min 36s\n",
      ":task_name:bundle_reservation_check_func\n",
      ":actor_name:ImplicitFunc\n",
      ":actor_name:train_model\n",
      "\n",
      "Trial train_model_14cbf_00001 started with configuration:\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00001 config             |\n",
      "+--------------------------------------------------+\n",
      "| batch_size                                    16 |\n",
      "| epochs                                        23 |\n",
      "| gamma                                        0.9 |\n",
      "| lr                                       0.01517 |\n",
      "| momentum                                 0.85765 |\n",
      "| step_size                                     10 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ":task_name:bundle_reservation_check_func\n",
      ":actor_name:ImplicitFunc\n",
      ":actor_name:train_model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4/7, Loss: 0.17673377506232385\n",
      "Save to checkpoint /tmp/tmpex0l1z5w/checkpoint.pt\n",
      "\n",
      "Trial status: 1 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 11:38:20. Total running time: 29min 41s\n",
      "Logical resource usage: 4.0/2 CPUs, 5120.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00001   RUNNING            23            10       0.9     0.857647                                                       |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00001 finished iteration 1 at 2024-02-06 11:38:20. Total running time: 29min 41s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00001 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         838.894 |\n",
      "| time_total_s                             838.894 |\n",
      "| training_iteration                             1 |\n",
      "| accuracy                                  0.9326 |\n",
      "| val_loss                                 0.17584 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 4\n",
      "Epoch 2/23, Loss: 0.297680066194894\n",
      "Save to checkpoint /tmp/tmpkyj792dd/checkpoint.pt\n",
      "\n",
      "Trial status: 1 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 11:40:01. Total running time: 31min 21s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00001   RUNNING            23            10       0.9     0.857647        1            838.894     0.175838     0.932599 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00001 finished iteration 2 at 2024-02-06 11:40:01. Total running time: 31min 21s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00001 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         100.233 |\n",
      "| time_total_s                             939.126 |\n",
      "| training_iteration                             2 |\n",
      "| accuracy                                 0.90217 |\n",
      "| val_loss                                  0.2671 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 2\n",
      "Epoch 5/7, Loss: 0.15279311094062242\n",
      "Save to checkpoint /tmp/tmpt1ujerpv/checkpoint.pt\n",
      "\n",
      "Trial status: 1 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 11:53:59. Total running time: 45min 19s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00001   RUNNING            23            10       0.9     0.857647        2            939.126     0.267099     0.90217  |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00001 finished iteration 3 at 2024-02-06 11:53:59. Total running time: 45min 19s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00001 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         837.919 |\n",
      "| time_total_s                             1777.05 |\n",
      "| training_iteration                             3 |\n",
      "| accuracy                                 0.92867 |\n",
      "| val_loss                                 0.19102 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 5\n",
      "Epoch 3/23, Loss: 0.2664987932379483\n",
      "Save to checkpoint /tmp/tmp4qkv4cd_/checkpoint.pt\n",
      "\n",
      "Trial status: 1 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 11:55:38. Total running time: 46min 58s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00001   RUNNING            23            10       0.9     0.857647        3           1777.05      0.191016     0.928673 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00001 finished iteration 4 at 2024-02-06 11:55:38. Total running time: 46min 58s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00001 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         99.0272 |\n",
      "| time_total_s                             1876.07 |\n",
      "| training_iteration                             4 |\n",
      "| accuracy                                 0.90577 |\n",
      "| val_loss                                 0.24754 |\n",
      "+--------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00001 completed after 4 iterations at 2024-02-06 11:55:38. Total running time: 46min 58s\n",
      ":task_name:bundle_reservation_check_func\n",
      ":actor_name:ImplicitFunc\n",
      ":actor_name:train_model\n",
      "\n",
      "Trial train_model_14cbf_00002 started with configuration:\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00002 config             |\n",
      "+--------------------------------------------------+\n",
      "| batch_size                                    16 |\n",
      "| epochs                                        15 |\n",
      "| gamma                                        0.9 |\n",
      "| lr                                       0.01517 |\n",
      "| momentum                                 0.86219 |\n",
      "| step_size                                     20 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ":task_name:bundle_reservation_check_func\n",
      ":actor_name:ImplicitFunc\n",
      ":actor_name:train_model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6/7, Loss: 0.14126097518839542\n",
      "Save to checkpoint /tmp/tmpez4cgmln/checkpoint.pt\n",
      "\n",
      "Trial status: 2 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 12:09:46. Total running time: 1hr 1min 6s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00002   RUNNING            15            20       0.9     0.862188                                                       |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00002 finished iteration 1 at 2024-02-06 12:09:46. Total running time: 1hr 1min 6s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00002 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         844.182 |\n",
      "| time_total_s                             844.182 |\n",
      "| training_iteration                             1 |\n",
      "| accuracy                                 0.93991 |\n",
      "| val_loss                                  0.1575 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 6\n",
      "Epoch 2/15, Loss: 0.24410248803316956\n",
      "Save to checkpoint /tmp/tmpcm8lapzl/checkpoint.pt\n",
      "\n",
      "Trial status: 2 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 12:11:23. Total running time: 1hr 2min 43s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00002   RUNNING            15            20       0.9     0.862188        1            844.182     0.157496     0.939906 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00002 finished iteration 2 at 2024-02-06 12:11:23. Total running time: 1hr 2min 43s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00002 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         96.9353 |\n",
      "| time_total_s                             941.117 |\n",
      "| training_iteration                             2 |\n",
      "| accuracy                                 0.91144 |\n",
      "| val_loss                                 0.23239 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 2\n",
      "Epoch 7/7, Loss: 0.12801058788159203\n",
      "Save to checkpoint /tmp/tmptpf_6os3/checkpoint.pt\n",
      "\n",
      "Trial status: 2 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 12:25:08. Total running time: 1hr 16min 29s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00002   RUNNING            15            20       0.9     0.862188        2            941.117     0.232389     0.911441 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00002 finished iteration 3 at 2024-02-06 12:25:08. Total running time: 1hr 16min 29s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00002 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         825.248 |\n",
      "| time_total_s                             1766.37 |\n",
      "| training_iteration                             3 |\n",
      "| accuracy                                 0.94121 |\n",
      "| val_loss                                 0.15928 |\n",
      "+--------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00002 completed after 3 iterations at 2024-02-06 12:25:08. Total running time: 1hr 16min 29s\n",
      ":task_name:bundle_reservation_check_func\n",
      ":actor_name:ImplicitFunc\n",
      ":actor_name:train_model\n",
      "\n",
      "Trial train_model_14cbf_00003 started with configuration:\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 config             |\n",
      "+--------------------------------------------------+\n",
      "| batch_size                                    16 |\n",
      "| epochs                                        18 |\n",
      "| gamma                                        0.1 |\n",
      "| lr                                       0.01517 |\n",
      "| momentum                                 0.87154 |\n",
      "| step_size                                     20 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ":task_name:bundle_reservation_check_func\n",
      ":actor_name:ImplicitFunc\n",
      ":actor_name:train_model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3/15, Loss: 0.22712422775793484\n",
      "Save to checkpoint /tmp/tmpuuwok2se/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 12:26:50. Total running time: 1hr 18min 10s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538                                                       |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 1 at 2024-02-06 12:26:50. Total running time: 1hr 18min 10s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         96.5838 |\n",
      "| time_total_s                             96.5838 |\n",
      "| training_iteration                             1 |\n",
      "| accuracy                                  0.9134 |\n",
      "| val_loss                                 0.22745 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 3\n",
      "Epoch 2/18, Loss: 0.21271463566900134\n",
      "Save to checkpoint /tmp/tmpg0n95af5/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 12:35:53. Total running time: 1hr 27min 13s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538        1            96.5838     0.227447     0.913404 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2           928.769      0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4          1876.07       0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3          1766.37       0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 2 at 2024-02-06 12:35:53. Total running time: 1hr 27min 13s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         543.339 |\n",
      "| time_total_s                             639.923 |\n",
      "| training_iteration                             2 |\n",
      "| accuracy                                 0.92278 |\n",
      "| val_loss                                 0.20625 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 2\n",
      "Epoch 3/18, Loss: 0.2018139957618947\n",
      "Save to checkpoint /tmp/tmpbzms6vog/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 12:46:19. Total running time: 1hr 37min 40s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538        2            639.923     0.206252     0.922783 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 3 at 2024-02-06 12:46:19. Total running time: 1hr 37min 40s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         626.201 |\n",
      "| time_total_s                             1266.12 |\n",
      "| training_iteration                             3 |\n",
      "| accuracy                                 0.92507 |\n",
      "| val_loss                                 0.19804 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 3\n",
      "Epoch 4/18, Loss: 0.18829119598731156\n",
      "Save to checkpoint /tmp/tmpgezl18ck/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 12:56:14. Total running time: 1hr 47min 35s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538        3           1266.12      0.198044     0.925074 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 4 at 2024-02-06 12:56:14. Total running time: 1hr 47min 35s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         595.102 |\n",
      "| time_total_s                             1861.23 |\n",
      "| training_iteration                             4 |\n",
      "| accuracy                                 0.92551 |\n",
      "| val_loss                                  0.1896 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 4\n",
      "Epoch 5/18, Loss: 0.1781524612888858\n",
      "Save to checkpoint /tmp/tmpu6aftlqv/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 13:06:04. Total running time: 1hr 57min 25s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538        4           1861.23      0.189601     0.92551  |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 5 at 2024-02-06 13:06:04. Total running time: 1hr 57min 25s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         589.649 |\n",
      "| time_total_s                             2450.87 |\n",
      "| training_iteration                             5 |\n",
      "| accuracy                                 0.92824 |\n",
      "| val_loss                                 0.18491 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 5\n",
      "Epoch 6/18, Loss: 0.16751628858853615\n",
      "Save to checkpoint /tmp/tmphifhoz4i/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 13:16:16. Total running time: 2hr 7min 37s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538        5           2450.87      0.18491      0.928236 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 6 at 2024-02-06 13:16:16. Total running time: 2hr 7min 37s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         612.016 |\n",
      "| time_total_s                             3062.89 |\n",
      "| training_iteration                             6 |\n",
      "| accuracy                                  0.9314 |\n",
      "| val_loss                                 0.17973 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 6\n",
      "Epoch 7/18, Loss: 0.15635249613189983\n",
      "Save to checkpoint /tmp/tmpl_y845ur/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 13:26:50. Total running time: 2hr 18min 10s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538        6           3062.89      0.179728     0.931399 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 7 at 2024-02-06 13:26:50. Total running time: 2hr 18min 10s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         633.652 |\n",
      "| time_total_s                             3696.54 |\n",
      "| training_iteration                             7 |\n",
      "| accuracy                                 0.93402 |\n",
      "| val_loss                                 0.17733 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 7\n",
      "Epoch 8/18, Loss: 0.15285586942856202\n",
      "Save to checkpoint /tmp/tmpezl3nh1w/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 13:37:29. Total running time: 2hr 28min 49s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538        7           3696.54      0.177326     0.934017 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 8 at 2024-02-06 13:37:29. Total running time: 2hr 28min 49s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         638.637 |\n",
      "| time_total_s                             4335.18 |\n",
      "| training_iteration                             8 |\n",
      "| accuracy                                 0.93402 |\n",
      "| val_loss                                 0.17413 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 8\n",
      "Epoch 9/18, Loss: 0.14275861580979138\n",
      "Save to checkpoint /tmp/tmp1mz6tfz3/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 13:47:50. Total running time: 2hr 39min 11s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538        8           4335.18      0.174126     0.934017 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 9 at 2024-02-06 13:47:50. Total running time: 2hr 39min 11s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         621.331 |\n",
      "| time_total_s                             4956.51 |\n",
      "| training_iteration                             9 |\n",
      "| accuracy                                 0.93587 |\n",
      "| val_loss                                 0.16568 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 9\n",
      "Epoch 10/18, Loss: 0.13603027266740933\n",
      "Save to checkpoint /tmp/tmpvgtzohal/checkpoint.pt\n",
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 13:58:20. Total running time: 2hr 49min 40s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538        9           4956.51      0.165684     0.935871 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Trial train_model_14cbf_00003 finished iteration 10 at 2024-02-06 13:58:20. Total running time: 2hr 49min 40s\n",
      "+--------------------------------------------------+\n",
      "| Trial train_model_14cbf_00003 result             |\n",
      "+--------------------------------------------------+\n",
      "| checkpoint_dir_name                              |\n",
      "| time_this_iter_s                         629.298 |\n",
      "| time_total_s                             5585.81 |\n",
      "| training_iteration                            10 |\n",
      "| accuracy                                   0.935 |\n",
      "| val_loss                                 0.16735 |\n",
      "+--------------------------------------------------+\n",
      "Start epoch 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2024-02-06 13:58:45,000\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 11/18, Loss: 0.12940649024106132\n",
      "Save to checkpoint /tmp/tmphi1n7f4w/checkpoint.pt\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2024-02-06 14:08:42,374\tWARNING tune.py:1057 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 14:08:42. Total running time: 3hr 0min 2s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538       10           5585.81      0.167346     0.934998 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "Trial status: 3 TERMINATED | 1 RUNNING\n",
      "Current time: 2024-02-06 14:08:42. Total running time: 3hr 0min 2s\n",
      "Logical resource usage: 2.0/2 CPUs, 2560.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                status         epochs     step_size     gamma     momentum     iter     total time (s)     val_loss     accuracy |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| train_model_14cbf_00003   RUNNING            18            20       0.1     0.871538       10           5585.81      0.167346     0.934998 |\n",
      "| train_model_14cbf_00000   TERMINATED         10            10       0.9     0.989646        2            928.769     0.357619     0.870106 |\n",
      "| train_model_14cbf_00001   TERMINATED         23            10       0.9     0.857647        4           1876.07      0.247543     0.905769 |\n",
      "| train_model_14cbf_00002   TERMINATED         15            20       0.9     0.862188        3           1766.37      0.15928      0.941215 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Best config:  {'lr': 0.0151688, 'batch_size': 16, 'epochs': 15, 'step_size': 20, 'gamma': 0.9, 'momentum': 0.8621876688576123}\n"
     ]
    }
   ],
   "source": [
    "best_config = get_best_params(config, train_model, scheduler, 15)\n",
    "print(\"Best config: \", best_config)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4sudUQQLONb",
    "outputId": "6ce435aa-9dee-4ecd-8850-ce946d304c7f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the model with optimal hyperparameters\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "bOkg4VSYu3AK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/train/_internal/session.py:638: UserWarning: `get_checkpoint` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 1\n",
      "Epoch 2/15, Loss: 0.5091636091942882\n",
      "Save to checkpoint /tmp/tmprzl5fac7/checkpoint.pt\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/train/_internal/session.py:638: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start epoch 2\n",
      "Epoch 3/15, Loss: 0.2262736892707978\n",
      "Save to checkpoint /tmp/tmpd3kgzwm5/checkpoint.pt\n",
      "Start epoch 3\n",
      "Epoch 4/15, Loss: 0.18148053778454445\n",
      "Save to checkpoint /tmp/tmphz2ic17h/checkpoint.pt\n",
      "Start epoch 4\n",
      "Epoch 5/15, Loss: 0.15612309563855048\n",
      "Save to checkpoint /tmp/tmpmuy4kuvp/checkpoint.pt\n",
      "Start epoch 5\n",
      "Epoch 6/15, Loss: 0.14424184967610248\n",
      "Save to checkpoint /tmp/tmp_499rf60/checkpoint.pt\n",
      "Start epoch 6\n",
      "Epoch 7/15, Loss: 0.1276284369279869\n",
      "Save to checkpoint /tmp/tmp40vtppi9/checkpoint.pt\n",
      "Start epoch 7\n",
      "Epoch 8/15, Loss: 0.11452750454196128\n",
      "Save to checkpoint /tmp/tmp2hzzazzw/checkpoint.pt\n",
      "Start epoch 8\n",
      "Epoch 9/15, Loss: 0.11665851295976591\n",
      "Save to checkpoint /tmp/tmpkd98t4_m/checkpoint.pt\n",
      "Start epoch 9\n",
      "Epoch 10/15, Loss: 0.10920110530014164\n",
      "Save to checkpoint /tmp/tmpsgcbymg3/checkpoint.pt\n",
      "Start epoch 10\n",
      "Epoch 11/15, Loss: 0.10262493730207822\n",
      "Save to checkpoint /tmp/tmpsu9cxt5u/checkpoint.pt\n",
      "Start epoch 11\n",
      "Epoch 12/15, Loss: 0.09575605211894765\n",
      "Save to checkpoint /tmp/tmpitck_ptu/checkpoint.pt\n",
      "Start epoch 12\n",
      "Epoch 13/15, Loss: 0.09176325905899022\n",
      "Save to checkpoint /tmp/tmpyvdtikfu/checkpoint.pt\n",
      "Start epoch 13\n",
      "Epoch 14/15, Loss: 0.09091411849245525\n",
      "Save to checkpoint /tmp/tmprqiwbnbt/checkpoint.pt\n",
      "Start epoch 14\n",
      "Epoch 15/15, Loss: 0.09029461813451119\n",
      "Save to checkpoint /tmp/tmpg7_liooz/checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "train_model(best_config)"
   ],
   "metadata": {
    "id": "f8p1bI-bu3AK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "86899faa-1858-4f60-b139-a0a3718e346b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), os.path.join(pretrained_models_dir, f\"chord_classifier.pth\"))"
   ],
   "metadata": {
    "id": "30vKzQU9ljnb"
   },
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(pretrained_models_dir, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchord_classifier.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transfer Learning"
   ],
   "metadata": {
    "collapsed": false,
    "id": "jz27k528LONc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the model, replace the last ResNet50 layer with an identity function that will just return features without changes and switch to evaluation mode."
   ],
   "metadata": {
    "collapsed": false,
    "id": "hXeuF5BCLONc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=7, bias=True)\n)"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model = load_model(os.path.join(pretrained_models_dir, \"chord_classifier_v3.pth\"))\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Identity()\n)"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc = nn.Identity()\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity()\n"
     ]
    }
   ],
   "source": [
    "print(model.fc)\n"
   ],
   "metadata": {
    "id": "yaMwWRWTLONd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a custom neural network which will accept features from pre-trained and fine tuned ResNet50 to make final classifications. This will allow for more flexibility in tuning the architecture for this particular task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# TODO: try softmax\n",
    "class ChordClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "        # Final layer\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract features using pre-trained and fine-tuned ResNet50 and save them into a HDF5 file on disk for training the classifier."
   ],
   "metadata": {
    "collapsed": false,
    "id": "ifh-T68RLONd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def create_h5_dataset(data_loader, file_name):\n",
    "    with h5py.File(file_name, 'w') as h5f:\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            print(f\"Processed {i} of {len(data_loader)}\")\n",
    "            inputs = inputs.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(inputs)\n",
    "\n",
    "            # Convert to numpy and write to disk\n",
    "            features_batch = output.cpu().detach().numpy()\n",
    "            labels_batch = labels.numpy()\n",
    "\n",
    "            # Create datasets for the first batch and then append for subsequent batches\n",
    "            if i == 0:\n",
    "                h5f.create_dataset('features', data=features_batch, maxshape=(None, features_batch.shape[1]), chunks=True)\n",
    "                h5f.create_dataset('labels', data=labels_batch, maxshape=(None,), chunks=True)\n",
    "            else:\n",
    "                h5f['features'].resize((h5f['features'].shape[0] + features_batch.shape[0]), axis=0)\n",
    "                h5f['features'][-features_batch.shape[0]:] = features_batch\n",
    "                h5f['labels'].resize((h5f['labels'].shape[0] + labels_batch.shape[0]), axis=0)\n",
    "                h5f['labels'][-labels_batch.shape[0]:] = labels_batch"
   ],
   "metadata": {
    "id": "ckZoipLbLONd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "train_features_set_file_name = \"features_labels.h5\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_h5_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[178], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m SpectrogramDataset(root_dir\u001B[38;5;241m=\u001B[39mpreprocessed_train_data_dir, transform\u001B[38;5;241m=\u001B[39mtransform)\n\u001B[1;32m      2\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m DataLoader(train_dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mcreate_h5_dataset\u001B[49m(train_loader, train_features_set_file_name)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'create_h5_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = SpectrogramDataset(root_dir=preprocessed_train_data_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "create_h5_dataset(train_loader, train_features_set_file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the same approach to generate test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "test_features_set_file_name = \"features_labels_test.h5\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = SpectrogramDataset(root_dir=preprocessed_test_data_dir, transform=transform)\n",
    "test_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "create_h5_dataset(test_loader, test_features_set_file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def load_dataset_from_file(file_name):\n",
    "    # Load features and labels\n",
    "    with h5py.File(file_name, 'r') as hf:\n",
    "        features = hf['features'][:]\n",
    "        labels = hf['labels'][:]\n",
    "\n",
    "    features = torch.tensor(features, dtype=torch.float)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return features, labels"
   ],
   "metadata": {
    "id": "B471IC_mLONd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "features, labels = load_dataset_from_file(train_features_set_file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the data into training and validation sets"
   ],
   "metadata": {
    "collapsed": false,
    "id": "IQRJkcpQLONd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_val, labels_train, labels_val = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "id": "7wYdk8djLONd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create datasets"
   ],
   "metadata": {
    "collapsed": false,
    "id": "8xkn3OMkLONd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36664 9167\n"
     ]
    }
   ],
   "source": [
    "train_features_dataset = TensorDataset(features_train, labels_train)\n",
    "val_features_dataset = TensorDataset(features_val, labels_val)\n",
    "\n",
    "print(len(train_features_dataset), len(val_features_dataset))"
   ],
   "metadata": {
    "id": "drRI6gJ0LONd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and validate"
   ],
   "metadata": {
    "collapsed": false,
    "id": "GjXCYSpYLONe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "classifier_model = ChordClassifier(input_size=features.shape[1], num_classes=len(torch.unique(labels)))\n"
   ],
   "metadata": {
    "id": "cDB8IJsyLONe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def train_classifier(config):\n",
    "    optimizer = torch.optim.Adam(classifier_model.parameters(), lr=config[\"lr\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_features_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_features_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = classifier_model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        classifier_model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                output = classifier_model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "        scheduler.step()\n",
    "        val_accuracy = correct/len(val_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {running_loss/len(train_loader)}, '\n",
    "              f'Val Loss: {val_loss/len(val_loader)}, Val Acc: {val_accuracy}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.24871177580331486, Val Loss: 0.11808191401313287, Val Acc: 0.956256136140504\n",
      "Epoch 2/30, Train Loss: 0.11476019234736975, Val Loss: 0.11781032309319604, Val Acc: 0.9559288753136249\n",
      "Epoch 3/30, Train Loss: 0.11587541372425057, Val Loss: 0.1258414049165031, Val Acc: 0.9530926148140068\n",
      "Epoch 4/30, Train Loss: 0.11205397626057187, Val Loss: 0.2629963352673928, Val Acc: 0.9499290934875095\n",
      "Epoch 5/30, Train Loss: 0.11881385422751867, Val Loss: 0.12289185982867928, Val Acc: 0.9596378313515872\n",
      "Epoch 6/30, Train Loss: 0.10460999446775063, Val Loss: 0.12149942191367338, Val Acc: 0.9582197011017781\n",
      "Epoch 7/30, Train Loss: 0.13009399303317631, Val Loss: 0.1574780030429841, Val Acc: 0.9576742663903131\n",
      "Epoch 8/30, Train Loss: 0.10969947083725254, Val Loss: 0.14063243748309487, Val Acc: 0.957456092505727\n",
      "Epoch 9/30, Train Loss: 0.10367407408263729, Val Loss: 0.1578856205732658, Val Acc: 0.9587651358132432\n",
      "Epoch 10/30, Train Loss: 0.1121424443465581, Val Loss: 0.17855030546722886, Val Acc: 0.957237918621141\n",
      "Epoch 11/30, Train Loss: 0.09522892605963659, Val Loss: 0.1612508173653833, Val Acc: 0.9600741791207592\n",
      "Epoch 12/30, Train Loss: 0.09246036998715326, Val Loss: 0.1742478161151703, Val Acc: 0.9602923530053452\n",
      "Epoch 13/30, Train Loss: 0.09179645578419142, Val Loss: 0.17169190369372458, Val Acc: 0.9602923530053452\n",
      "Epoch 14/30, Train Loss: 0.09112288839555245, Val Loss: 0.18647748883645648, Val Acc: 0.9601832660630523\n",
      "Epoch 15/30, Train Loss: 0.09092491301681262, Val Loss: 0.1894431332297394, Val Acc: 0.9600741791207592\n",
      "Epoch 16/30, Train Loss: 0.09045145625364347, Val Loss: 0.2063766692801073, Val Acc: 0.9602923530053452\n",
      "Epoch 17/30, Train Loss: 0.09043424545713928, Val Loss: 0.19798060364045164, Val Acc: 0.9602923530053452\n",
      "Epoch 18/30, Train Loss: 0.09017728887033186, Val Loss: 0.21465038789349383, Val Acc: 0.9602923530053452\n",
      "Epoch 19/30, Train Loss: 0.09009657711410562, Val Loss: 0.23580575944914708, Val Acc: 0.9601832660630523\n",
      "Epoch 20/30, Train Loss: 0.08996056831589755, Val Loss: 0.22546669988744863, Val Acc: 0.9604014399476383\n",
      "Epoch 21/30, Train Loss: 0.08923659798843239, Val Loss: 0.22940972342412178, Val Acc: 0.9604014399476383\n",
      "Epoch 22/30, Train Loss: 0.08920299009476668, Val Loss: 0.23419380437421547, Val Acc: 0.9604014399476383\n",
      "Epoch 23/30, Train Loss: 0.08915398318291566, Val Loss: 0.23789253026475266, Val Acc: 0.9604014399476383\n",
      "Epoch 24/30, Train Loss: 0.08912765712091766, Val Loss: 0.24313227162132897, Val Acc: 0.9604014399476383\n",
      "Epoch 25/30, Train Loss: 0.08912961437905881, Val Loss: 0.24622391539479738, Val Acc: 0.9604014399476383\n",
      "Epoch 26/30, Train Loss: 0.08906523247925499, Val Loss: 0.2500448281500993, Val Acc: 0.9604014399476383\n",
      "Epoch 27/30, Train Loss: 0.08903767168828156, Val Loss: 0.2513781292754611, Val Acc: 0.9604014399476383\n",
      "Epoch 28/30, Train Loss: 0.08900275836633588, Val Loss: 0.2549225427029791, Val Acc: 0.9604014399476383\n",
      "Epoch 29/30, Train Loss: 0.08896876126174219, Val Loss: 0.25745149445427845, Val Acc: 0.9602923530053452\n",
      "Epoch 30/30, Train Loss: 0.0889546166162593, Val Loss: 0.2588888976030914, Val Acc: 0.9604014399476383\n"
     ]
    }
   ],
   "source": [
    "train_classifier({\"lr\": 0.02, \"batch_size\": 16, \"epochs\": 30})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3dZv3SmcLONf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "data": {
      "text/plain": "8646"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = SpectrogramDataset(root_dir=preprocessed_test_data_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "len(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "data": {
      "text/plain": "8646"
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_features, classifier_labels = load_dataset_from_file(test_features_set_file_name)\n",
    "\n",
    "test_classifier_dataset = TensorDataset(classifier_features, classifier_labels)\n",
    "test_classifier_loader = DataLoader(test_classifier_dataset, batch_size=32, shuffle=False)\n",
    "len(test_classifier_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def get_metrics(model_to_test, data_loader):\n",
    "    model_to_test.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    batch_count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            batch_count += 1\n",
    "            print(\"handle batch\", batch_count)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model_to_test(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "    recall = recall_score(all_targets, all_predictions, average='macro')\n",
    "    f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "    conf_matrix = confusion_matrix(all_targets, all_predictions, labels=range(len(chord_labels)))\n",
    "\n",
    "    return precision, recall, f1, conf_matrix\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "PDGFpUk0u3AL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ea84e68e-1feb-4a96-c4c7-cb20b32f210c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "ChordClassifier(\n  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n  (relu): ReLU()\n  (fc2): Linear(in_features=512, out_features=7, bias=True)\n  (softmax): Softmax(dim=1)\n)"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [
    "classifier_precision, classifier_recall, classifier_f1, classifier_conf_matrix = get_metrics(classifier_model, test_classifier_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9035940999683936 0.8964606527671436 0.8976557762603086\n"
     ]
    }
   ],
   "source": [
    "print(classifier_precision, classifier_recall, classifier_f1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.9021650034095429 0.8961107826195616 0.8971024453227924"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.9035940999683936 0.8964606527671436 0.8976557762603086"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Need to reload the ResNet50 model to restore the last layer for comparison."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=7, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model = load_model(os.path.join(pretrained_models_dir, \"chord_classifier_v3.pth\"))\n",
    "model.to(device)\n",
    "print(model.fc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle batch 1\n",
      "handle batch 2\n",
      "handle batch 3\n",
      "handle batch 4\n",
      "handle batch 5\n",
      "handle batch 6\n",
      "handle batch 7\n",
      "handle batch 8\n",
      "handle batch 9\n",
      "handle batch 10\n",
      "handle batch 11\n",
      "handle batch 12\n",
      "handle batch 13\n",
      "handle batch 14\n",
      "handle batch 15\n",
      "handle batch 16\n",
      "handle batch 17\n",
      "handle batch 18\n",
      "handle batch 19\n",
      "handle batch 20\n",
      "handle batch 21\n",
      "handle batch 22\n",
      "handle batch 23\n",
      "handle batch 24\n",
      "handle batch 25\n",
      "handle batch 26\n",
      "handle batch 27\n",
      "handle batch 28\n",
      "handle batch 29\n",
      "handle batch 30\n",
      "handle batch 31\n",
      "handle batch 32\n",
      "handle batch 33\n",
      "handle batch 34\n",
      "handle batch 35\n",
      "handle batch 36\n",
      "handle batch 37\n",
      "handle batch 38\n",
      "handle batch 39\n",
      "handle batch 40\n",
      "handle batch 41\n",
      "handle batch 42\n",
      "handle batch 43\n",
      "handle batch 44\n",
      "handle batch 45\n",
      "handle batch 46\n",
      "handle batch 47\n",
      "handle batch 48\n",
      "handle batch 49\n",
      "handle batch 50\n",
      "handle batch 51\n",
      "handle batch 52\n",
      "handle batch 53\n",
      "handle batch 54\n",
      "handle batch 55\n",
      "handle batch 56\n",
      "handle batch 57\n",
      "handle batch 58\n",
      "handle batch 59\n",
      "handle batch 60\n",
      "handle batch 61\n",
      "handle batch 62\n",
      "handle batch 63\n",
      "handle batch 64\n",
      "handle batch 65\n",
      "handle batch 66\n",
      "handle batch 67\n",
      "handle batch 68\n",
      "handle batch 69\n",
      "handle batch 70\n",
      "handle batch 71\n",
      "handle batch 72\n",
      "handle batch 73\n",
      "handle batch 74\n",
      "handle batch 75\n",
      "handle batch 76\n",
      "handle batch 77\n",
      "handle batch 78\n",
      "handle batch 79\n",
      "handle batch 80\n",
      "handle batch 81\n",
      "handle batch 82\n",
      "handle batch 83\n",
      "handle batch 84\n",
      "handle batch 85\n",
      "handle batch 86\n",
      "handle batch 87\n",
      "handle batch 88\n",
      "handle batch 89\n",
      "handle batch 90\n",
      "handle batch 91\n",
      "handle batch 92\n",
      "handle batch 93\n",
      "handle batch 94\n",
      "handle batch 95\n",
      "handle batch 96\n",
      "handle batch 97\n",
      "handle batch 98\n",
      "handle batch 99\n",
      "handle batch 100\n",
      "handle batch 101\n",
      "handle batch 102\n",
      "handle batch 103\n",
      "handle batch 104\n",
      "handle batch 105\n",
      "handle batch 106\n",
      "handle batch 107\n",
      "handle batch 108\n",
      "handle batch 109\n",
      "handle batch 110\n",
      "handle batch 111\n",
      "handle batch 112\n",
      "handle batch 113\n",
      "handle batch 114\n",
      "handle batch 115\n",
      "handle batch 116\n",
      "handle batch 117\n",
      "handle batch 118\n",
      "handle batch 119\n",
      "handle batch 120\n",
      "handle batch 121\n",
      "handle batch 122\n",
      "handle batch 123\n",
      "handle batch 124\n",
      "handle batch 125\n",
      "handle batch 126\n",
      "handle batch 127\n",
      "handle batch 128\n",
      "handle batch 129\n",
      "handle batch 130\n",
      "handle batch 131\n",
      "handle batch 132\n",
      "handle batch 133\n",
      "handle batch 134\n",
      "handle batch 135\n",
      "handle batch 136\n",
      "handle batch 137\n",
      "handle batch 138\n",
      "handle batch 139\n",
      "handle batch 140\n",
      "handle batch 141\n",
      "handle batch 142\n",
      "handle batch 143\n",
      "handle batch 144\n",
      "handle batch 145\n",
      "handle batch 146\n",
      "handle batch 147\n",
      "handle batch 148\n",
      "handle batch 149\n",
      "handle batch 150\n",
      "handle batch 151\n",
      "handle batch 152\n",
      "handle batch 153\n",
      "handle batch 154\n",
      "handle batch 155\n",
      "handle batch 156\n",
      "handle batch 157\n",
      "handle batch 158\n",
      "handle batch 159\n",
      "handle batch 160\n",
      "handle batch 161\n",
      "handle batch 162\n",
      "handle batch 163\n",
      "handle batch 164\n",
      "handle batch 165\n",
      "handle batch 166\n",
      "handle batch 167\n",
      "handle batch 168\n",
      "handle batch 169\n",
      "handle batch 170\n",
      "handle batch 171\n",
      "handle batch 172\n",
      "handle batch 173\n",
      "handle batch 174\n",
      "handle batch 175\n",
      "handle batch 176\n",
      "handle batch 177\n",
      "handle batch 178\n",
      "handle batch 179\n",
      "handle batch 180\n",
      "handle batch 181\n",
      "handle batch 182\n",
      "handle batch 183\n",
      "handle batch 184\n",
      "handle batch 185\n",
      "handle batch 186\n",
      "handle batch 187\n",
      "handle batch 188\n",
      "handle batch 189\n",
      "handle batch 190\n",
      "handle batch 191\n",
      "handle batch 192\n",
      "handle batch 193\n",
      "handle batch 194\n",
      "handle batch 195\n",
      "handle batch 196\n",
      "handle batch 197\n",
      "handle batch 198\n",
      "handle batch 199\n",
      "handle batch 200\n",
      "handle batch 201\n",
      "handle batch 202\n",
      "handle batch 203\n",
      "handle batch 204\n",
      "handle batch 205\n",
      "handle batch 206\n",
      "handle batch 207\n",
      "handle batch 208\n",
      "handle batch 209\n",
      "handle batch 210\n",
      "handle batch 211\n",
      "handle batch 212\n",
      "handle batch 213\n",
      "handle batch 214\n",
      "handle batch 215\n",
      "handle batch 216\n",
      "handle batch 217\n",
      "handle batch 218\n",
      "handle batch 219\n",
      "handle batch 220\n",
      "handle batch 221\n",
      "handle batch 222\n",
      "handle batch 223\n",
      "handle batch 224\n",
      "handle batch 225\n",
      "handle batch 226\n",
      "handle batch 227\n",
      "handle batch 228\n",
      "handle batch 229\n",
      "handle batch 230\n",
      "handle batch 231\n",
      "handle batch 232\n",
      "handle batch 233\n",
      "handle batch 234\n",
      "handle batch 235\n",
      "handle batch 236\n",
      "handle batch 237\n",
      "handle batch 238\n",
      "handle batch 239\n",
      "handle batch 240\n",
      "handle batch 241\n",
      "handle batch 242\n",
      "handle batch 243\n",
      "handle batch 244\n",
      "handle batch 245\n",
      "handle batch 246\n",
      "handle batch 247\n",
      "handle batch 248\n",
      "handle batch 249\n",
      "handle batch 250\n",
      "handle batch 251\n",
      "handle batch 252\n",
      "handle batch 253\n",
      "handle batch 254\n",
      "handle batch 255\n",
      "handle batch 256\n",
      "handle batch 257\n",
      "handle batch 258\n",
      "handle batch 259\n",
      "handle batch 260\n",
      "handle batch 261\n",
      "handle batch 262\n",
      "handle batch 263\n",
      "handle batch 264\n",
      "handle batch 265\n",
      "handle batch 266\n",
      "handle batch 267\n",
      "handle batch 268\n",
      "handle batch 269\n",
      "handle batch 270\n",
      "handle batch 271\n",
      "handle batch 272\n",
      "handle batch 273\n",
      "handle batch 274\n",
      "handle batch 275\n",
      "handle batch 276\n",
      "handle batch 277\n",
      "handle batch 278\n",
      "handle batch 279\n",
      "handle batch 280\n",
      "handle batch 281\n",
      "handle batch 282\n",
      "handle batch 283\n",
      "handle batch 284\n",
      "handle batch 285\n",
      "handle batch 286\n",
      "handle batch 287\n",
      "handle batch 288\n",
      "handle batch 289\n",
      "handle batch 290\n",
      "handle batch 291\n",
      "handle batch 292\n",
      "handle batch 293\n",
      "handle batch 294\n",
      "handle batch 295\n",
      "handle batch 296\n",
      "handle batch 297\n",
      "handle batch 298\n",
      "handle batch 299\n",
      "handle batch 300\n",
      "handle batch 301\n",
      "handle batch 302\n",
      "handle batch 303\n",
      "handle batch 304\n",
      "handle batch 305\n",
      "handle batch 306\n",
      "handle batch 307\n",
      "handle batch 308\n",
      "handle batch 309\n",
      "handle batch 310\n",
      "handle batch 311\n",
      "handle batch 312\n",
      "handle batch 313\n",
      "handle batch 314\n",
      "handle batch 315\n",
      "handle batch 316\n",
      "handle batch 317\n",
      "handle batch 318\n",
      "handle batch 319\n",
      "handle batch 320\n",
      "handle batch 321\n",
      "handle batch 322\n",
      "handle batch 323\n",
      "handle batch 324\n",
      "handle batch 325\n",
      "handle batch 326\n",
      "handle batch 327\n",
      "handle batch 328\n",
      "handle batch 329\n",
      "handle batch 330\n",
      "handle batch 331\n",
      "handle batch 332\n",
      "handle batch 333\n",
      "handle batch 334\n",
      "handle batch 335\n",
      "handle batch 336\n",
      "handle batch 337\n",
      "handle batch 338\n",
      "handle batch 339\n",
      "handle batch 340\n",
      "handle batch 341\n",
      "handle batch 342\n",
      "handle batch 343\n",
      "handle batch 344\n",
      "handle batch 345\n",
      "handle batch 346\n",
      "handle batch 347\n",
      "handle batch 348\n",
      "handle batch 349\n",
      "handle batch 350\n",
      "handle batch 351\n",
      "handle batch 352\n",
      "handle batch 353\n",
      "handle batch 354\n",
      "handle batch 355\n",
      "handle batch 356\n",
      "handle batch 357\n",
      "handle batch 358\n",
      "handle batch 359\n",
      "handle batch 360\n",
      "handle batch 361\n",
      "handle batch 362\n",
      "handle batch 363\n",
      "handle batch 364\n",
      "handle batch 365\n",
      "handle batch 366\n",
      "handle batch 367\n",
      "handle batch 368\n",
      "handle batch 369\n",
      "handle batch 370\n",
      "handle batch 371\n",
      "handle batch 372\n",
      "handle batch 373\n",
      "handle batch 374\n",
      "handle batch 375\n",
      "handle batch 376\n",
      "handle batch 377\n",
      "handle batch 378\n",
      "handle batch 379\n",
      "handle batch 380\n",
      "handle batch 381\n",
      "handle batch 382\n",
      "handle batch 383\n",
      "handle batch 384\n",
      "handle batch 385\n",
      "handle batch 386\n",
      "handle batch 387\n",
      "handle batch 388\n",
      "handle batch 389\n",
      "handle batch 390\n",
      "handle batch 391\n",
      "handle batch 392\n",
      "handle batch 393\n",
      "handle batch 394\n",
      "handle batch 395\n",
      "handle batch 396\n",
      "handle batch 397\n",
      "handle batch 398\n",
      "handle batch 399\n",
      "handle batch 400\n",
      "handle batch 401\n",
      "handle batch 402\n",
      "handle batch 403\n",
      "handle batch 404\n",
      "handle batch 405\n",
      "handle batch 406\n",
      "handle batch 407\n",
      "handle batch 408\n",
      "handle batch 409\n",
      "handle batch 410\n",
      "handle batch 411\n",
      "handle batch 412\n",
      "handle batch 413\n",
      "handle batch 414\n",
      "handle batch 415\n",
      "handle batch 416\n",
      "handle batch 417\n",
      "handle batch 418\n",
      "handle batch 419\n",
      "handle batch 420\n",
      "handle batch 421\n",
      "handle batch 422\n",
      "handle batch 423\n",
      "handle batch 424\n",
      "handle batch 425\n",
      "handle batch 426\n",
      "handle batch 427\n",
      "handle batch 428\n",
      "handle batch 429\n",
      "handle batch 430\n",
      "handle batch 431\n",
      "handle batch 432\n",
      "handle batch 433\n",
      "handle batch 434\n",
      "handle batch 435\n",
      "handle batch 436\n",
      "handle batch 437\n",
      "handle batch 438\n",
      "handle batch 439\n",
      "handle batch 440\n",
      "handle batch 441\n",
      "handle batch 442\n",
      "handle batch 443\n",
      "handle batch 444\n",
      "handle batch 445\n",
      "handle batch 446\n",
      "handle batch 447\n",
      "handle batch 448\n",
      "handle batch 449\n",
      "handle batch 450\n",
      "handle batch 451\n",
      "handle batch 452\n",
      "handle batch 453\n",
      "handle batch 454\n",
      "handle batch 455\n",
      "handle batch 456\n",
      "handle batch 457\n",
      "handle batch 458\n",
      "handle batch 459\n",
      "handle batch 460\n",
      "handle batch 461\n",
      "handle batch 462\n",
      "handle batch 463\n",
      "handle batch 464\n",
      "handle batch 465\n",
      "handle batch 466\n",
      "handle batch 467\n",
      "handle batch 468\n",
      "handle batch 469\n",
      "handle batch 470\n",
      "handle batch 471\n",
      "handle batch 472\n",
      "handle batch 473\n",
      "handle batch 474\n",
      "handle batch 475\n",
      "handle batch 476\n",
      "handle batch 477\n",
      "handle batch 478\n",
      "handle batch 479\n",
      "handle batch 480\n",
      "handle batch 481\n",
      "handle batch 482\n",
      "handle batch 483\n",
      "handle batch 484\n",
      "handle batch 485\n",
      "handle batch 486\n",
      "handle batch 487\n",
      "handle batch 488\n",
      "handle batch 489\n",
      "handle batch 490\n",
      "handle batch 491\n",
      "handle batch 492\n",
      "handle batch 493\n",
      "handle batch 494\n",
      "handle batch 495\n",
      "handle batch 496\n",
      "handle batch 497\n",
      "handle batch 498\n",
      "handle batch 499\n",
      "handle batch 500\n",
      "handle batch 501\n",
      "handle batch 502\n",
      "handle batch 503\n",
      "handle batch 504\n",
      "handle batch 505\n",
      "handle batch 506\n",
      "handle batch 507\n",
      "handle batch 508\n",
      "handle batch 509\n",
      "handle batch 510\n",
      "handle batch 511\n",
      "handle batch 512\n",
      "handle batch 513\n",
      "handle batch 514\n",
      "handle batch 515\n",
      "handle batch 516\n",
      "handle batch 517\n",
      "handle batch 518\n",
      "handle batch 519\n",
      "handle batch 520\n",
      "handle batch 521\n",
      "handle batch 522\n",
      "handle batch 523\n",
      "handle batch 524\n",
      "handle batch 525\n",
      "handle batch 526\n",
      "handle batch 527\n",
      "handle batch 528\n",
      "handle batch 529\n",
      "handle batch 530\n",
      "handle batch 531\n",
      "handle batch 532\n",
      "handle batch 533\n",
      "handle batch 534\n",
      "handle batch 535\n",
      "handle batch 536\n",
      "handle batch 537\n",
      "handle batch 538\n",
      "handle batch 539\n",
      "handle batch 540\n",
      "handle batch 541\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, conf_matrix = get_metrics(model, test_loader)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9045474853508028 0.8953034375710812 0.8971718566412676\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, f1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"ResNet50 Precision: {precision}, Classifier Precision: {classifier_precision}\")\n",
    "print(f\"ResNet50 Recall: {recall}, Classifier Recall: {classifier_recall}\")\n",
    "print(f\"ResNet50 F1 Score: {f1}, Classifier F1 Score\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metrics received on test dataset:\n",
    "\n",
    "Precision: 0.9044754119873304\n",
    "\n",
    "Recall: 0.8930117832821793\n",
    "\n",
    "F1 Score: 0.8953096711745837"
   ],
   "metadata": {
    "collapsed": false,
    "id": "AmMORCKTu3AL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "id": "z0U3NWvaLONf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrices(conf_matrix1, conf_matrix2, labels, title1='Confusion Matrix 1', title2='Confusion Matrix 2'):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 8))  # 1 row, 2 columns\n",
    "\n",
    "    # Plot first confusion matrix\n",
    "    sns.heatmap(conf_matrix1, annot=True, fmt='g', ax=ax[0], xticklabels=labels, yticklabels=labels, cmap='viridis')\n",
    "    ax[0].set_title(title1)\n",
    "    ax[0].set_xlabel('Predicted labels')\n",
    "    ax[0].set_ylabel('True labels')\n",
    "\n",
    "    # Plot second confusion matrix\n",
    "    sns.heatmap(conf_matrix2, annot=True, fmt='g', ax=ax[1], xticklabels=labels, yticklabels=labels, cmap='viridis')\n",
    "    ax[1].set_title(title2)\n",
    "    ax[1].set_xlabel('Predicted labels')\n",
    "    ax[1].set_ylabel('True labels')\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to not overlap\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "id": "mB0dq8E7u3AL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "outputId": "fb12c976-5560-46dc-bbc3-7840124a41ff"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 2000x800 with 4 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrices(conf_matrix, classifier_conf_matrix, chord_labels, \"ResNet50\", \"Classifier\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Track splitting\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "rv762AGOu2_4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "songs_dir = \"songs\"\n",
    "separated_songs_dir = os.path.join(songs_dir, \"separated\")\n",
    "song_file_name = \"Have-You-Ever-Seen-The-Rain\"\n",
    "song_path = os.path.join(songs_dir, song_file_name + \".mp3\")"
   ],
   "metadata": {
    "id": "A2PY9iuau2_4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extracting the guitar track from the uploaded song. Let's check this feature on the Have You Ever Seen The Rain by Creedence Clearwater Revival which has a distinctive guitar track.\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "REPXTaEau2_5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(song_path)\n"
   ],
   "metadata": {
    "id": "FLg2dJ-xu2_5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spleeter will divide the song into 4 separate tracks: bass, drums, vocals and other. The guitar will be contained in \"other\"."
   ],
   "metadata": {
    "collapsed": false,
    "id": "UXG6YViZu2_5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "command = f\"spleeter separate -p spleeter:4stems -o {separated_songs_dir} {song_path}\"\n",
    "subprocess.run(command, shell=True)"
   ],
   "metadata": {
    "id": "pbKjiheMu2_5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "id": "20fDQaLnu2_5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "guitar_track_path = os.path.join(separated_songs_dir, song_file_name, \"other.mp3\")\n",
    "\n",
    "Audio(guitar_track_path)\n"
   ],
   "metadata": {
    "id": "I25XBUP8u2_5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating spectrograms from the extracted track\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "QXqSCBagu2_5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [
    "output_dir = Path(os.path.join(\"data\", \"extracted\", song_file_name))"
   ],
   "metadata": {
    "id": "lercTZzau2_6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function will process each segment of a track and convert it to a spectrogram. The spectrogram will be returned to be used as input to CNN and also will be saved to disk so that if we want to process the same track again, we could use existing data."
   ],
   "metadata": {
    "collapsed": false,
    "id": "2gaZcaQEu2_6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function detects beat length and generates a spectrogram for each beat. Currently, it returns an array of spectrograms. Later on, predictions of a chord with CNN will be plugged in and it will return a list of predictions."
   ],
   "metadata": {
    "collapsed": false,
    "id": "e569jcHEu2_6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def process_track(audio_path, output_dir):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "    print(f\"Track tempo is {tempo}\")\n",
    "    beat_duration = 60.0 / tempo  # Duration of a beat in seconds\n",
    "\n",
    "    print(f\"Beat duration is {beat_duration} seconds\")\n",
    "\n",
    "    # Calculate the number of samples per beat\n",
    "    samples_per_beat = int(beat_duration * sr)\n",
    "\n",
    "    print(f\"Samples per beat: {samples_per_beat}\")\n",
    "\n",
    "    spectrograms = []\n",
    "    for i in range(0, len(y), samples_per_beat):\n",
    "        end_frame = i + samples_per_beat\n",
    "        if end_frame > len(y):\n",
    "            end_frame = len(y)  # Adjust the end frame for the last segment\n",
    "\n",
    "        segment = y[i:end_frame]\n",
    "        filename = f'spectrogram_{i // samples_per_beat}.jpg'\n",
    "        print(f\"Create spectrogram {filename}\")\n",
    "        spectrogram = create_spectrogram(segment, sr, os.path.join(output_dir, filename))\n",
    "        spectrograms.append(spectrogram)\n",
    "\n",
    "    return spectrograms\n"
   ],
   "metadata": {
    "id": "kEvvfu7lu2_6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To keep things simple, we will consider that the track already processed if the directory with the song name already exists. We can implement more sophisticated and robust checks like file hash sum later."
   ],
   "metadata": {
    "collapsed": false,
    "id": "LWoGfR9Gu2_6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    if os.path.exists(output_dir):\n",
    "        print(\"The track is already processed\", output_dir)\n",
    "    else:\n",
    "        os.makedirs(output_dir)\n",
    "        print(\"Processing track\", output_dir)\n",
    "        spectrograms = process_track(guitar_track_path, output_dir)\n",
    "\n",
    "        print(spectrograms[:10])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    os.removedirs(output_dir)\n"
   ],
   "metadata": {
    "id": "RDxB-WYXu3AE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's visualize an example of generated spectrogram"
   ],
   "metadata": {
    "collapsed": false,
    "id": "G_ypZyhxu3AE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "files = os.listdir(output_dir)\n",
    "image_path = os.path.join(output_dir, files[50])\n",
    "\n",
    "print(f\"Displaying the image at {image_path}\")\n",
    "\n",
    "img = mpimg.imread(image_path)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "LgWhiYrlu3AE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "eoy3YSI8u3AL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_spectrogram(file_path):\n",
    "    image = Image.open(file_path).convert('RGB')\n",
    "    return transform(image)"
   ],
   "metadata": {
    "id": "TMlaZwv9u3AL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Switch to evaluation mode and convert logits to probabilities using softmax\n"
   ],
   "metadata": {
    "id": "AmN4yNA492Qh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "classifier_model.eval()\n",
    "\n",
    "# Define the softmax function\n",
    "softmax = torch.nn.Softmax(dim=1)"
   ],
   "metadata": {
    "id": "y7dabTIL92sR"
   },
   "execution_count": 310,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sort spectrograms by file name as it contains its order number. We need to have it ordered to be able to output it aligned with track timeline."
   ],
   "metadata": {
    "id": "Y6ajig6M99FI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [
    {
     "data": {
      "text/plain": "PosixPath('data/extracted/Have-You-Ever-Seen-The-Rain')"
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ],
   "metadata": {
    "id": "7pCSqfliLONg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# List all jpg files in the output directory\n",
    "file_names = [file for file in os.listdir(output_dir) if file.endswith('.jpg')]\n",
    "\n",
    "# Sort the file names (natural sort or simple alphanumeric sort)\n",
    "file_names.sort(key=lambda f: int(f.split('_')[-1].split('.')[0]))\n",
    "\n",
    "spectrograms = [load_spectrogram(os.path.join(output_dir, file)) for file in file_names]"
   ],
   "metadata": {
    "id": "ZnouPWsO99qI"
   },
   "execution_count": 312,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make predictions for each spectrogram. For each prediction we get top N results. We also map them to labels for output."
   ],
   "metadata": {
    "id": "jTse-xad-e5h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "index_to_label = {v: k for k,v in label_to_idx.items()}\n",
    "\n",
    "N = 3  # Number of top predictions\n",
    "\n",
    "top_labels_all = []\n",
    "top_confidences_all = []\n",
    "\n",
    "for spectrogram in spectrograms:\n",
    "    # make sure spectrograms are on the same device as the model, otherwise there will be input type mismatch\n",
    "    spectrogram = spectrogram.to(device)\n",
    "    # Apply the model and get the prediction\n",
    "    output = classifier_model(model(spectrogram.unsqueeze(0)))  # Add batch dimension\n",
    "    probabilities = softmax(output)\n",
    "\n",
    "    # Get the top N predictions\n",
    "    top_probs, top_preds = torch.topk(probabilities, N, dim=1)\n",
    "\n",
    "    # Convert to labels and confidences\n",
    "    top_labels = [index_to_label[pred.item()] for pred in top_preds[0]]\n",
    "    top_confidences = [prob.item() for prob in top_probs[0]]\n",
    "\n",
    "    top_labels_all.append(top_labels)\n",
    "    top_confidences_all.append(top_confidences)"
   ],
   "metadata": {
    "id": "qfmCyTJg-Ysq"
   },
   "execution_count": 313,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output"
   ],
   "metadata": {
    "id": "tJ1KM4F7-3hP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* For each beat, we get top N predictions\n",
    "* Low confidence predictions with threshold lower than 0.3 will be discarded\n",
    "* We will consider two adjacents beats at once. First, chords that appear in both beats predictions will be chosen. If there are several such chords, then the chord with the highest average confidence will be chosen."
   ],
   "metadata": {
    "id": "b-hMILEE-80c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "id": "RRRXzre5LONh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for file, labels, confidences in zip(file_names[:20], top_labels_all[:20], top_confidences_all[:20]):\n",
    "    print(f\"{file}:\")\n",
    "    for label, confidence in zip(labels, confidences):\n",
    "        print(f\"  {label}: {confidence:.4f}\")"
   ],
   "metadata": {
    "id": "I35BkV0O-0hb"
   },
   "execution_count": 314,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrogram_0.jpg:\n",
      "  Am: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_1.jpg:\n",
      "  Am: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_2.jpg:\n",
      "  Am: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_3.jpg:\n",
      "  Am: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_4.jpg:\n",
      "  Am: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_5.jpg:\n",
      "  F: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_6.jpg:\n",
      "  F: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_7.jpg:\n",
      "  F: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_8.jpg:\n",
      "  F: 1.0000\n",
      "  C: 0.0000\n",
      "  Bb: 0.0000\n",
      "spectrogram_9.jpg:\n",
      "  C: 1.0000\n",
      "  Bb: 0.0000\n",
      "  Am: 0.0000\n",
      "spectrogram_10.jpg:\n",
      "  C: 1.0000\n",
      "  G: 0.0000\n",
      "  Am: 0.0000\n",
      "spectrogram_11.jpg:\n",
      "  C: 1.0000\n",
      "  G: 0.0000\n",
      "  Am: 0.0000\n",
      "spectrogram_12.jpg:\n",
      "  C: 1.0000\n",
      "  G: 0.0000\n",
      "  Dm: 0.0000\n",
      "spectrogram_13.jpg:\n",
      "  G: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_14.jpg:\n",
      "  G: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_15.jpg:\n",
      "  Em: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_16.jpg:\n",
      "  Em: 1.0000\n",
      "  Bb: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_17.jpg:\n",
      "  Em: 1.0000\n",
      "  G: 0.0000\n",
      "  C: 0.0000\n",
      "spectrogram_18.jpg:\n",
      "  Em: 1.0000\n",
      "  C: 0.0000\n",
      "  G: 0.0000\n",
      "spectrogram_19.jpg:\n",
      "  C: 1.0000\n",
      "  G: 0.0000\n",
      "  Dm: 0.0000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "def map_label_to_confidence(labels, confidences):\n",
    "    return {label: confidence for label, confidence in zip(labels, confidences)}"
   ],
   "metadata": {
    "id": "jg_iBgLwLONh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "def get_with_max_confidence(common_labels, prev_labels_to_confidence, labels_to_confidence):\n",
    "    highest_conf_label = None\n",
    "    highest_confidence = 0\n",
    "\n",
    "    for label in common_labels:\n",
    "        avg_conf = (prev_labels_to_confidence.get(label, 0) + labels_to_confidence.get(label, 0)) / 2\n",
    "        if avg_conf > highest_confidence:\n",
    "            highest_confidence = avg_conf\n",
    "            highest_conf_label = label\n",
    "\n",
    "    return highest_conf_label, highest_confidence"
   ],
   "metadata": {
    "id": "I9XcA3g3LONh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def process_chord_predictions(top_labels_all, top_confidences_all, confidence_threshold=0.3):\n",
    "    chord_predictions = []\n",
    "\n",
    "    for i in range(1, len(top_labels_all), 2):\n",
    "        prev_labels = top_labels_all[i - 1]\n",
    "        labels = top_labels_all[i]\n",
    "        prev_confidences = top_confidences_all[i - 1]\n",
    "        confidences = top_confidences_all[i]\n",
    "\n",
    "        prev_labels_to_confidence = map_label_to_confidence(prev_labels, prev_confidences)\n",
    "        labels_to_confidence = map_label_to_confidence(labels, confidences)\n",
    "\n",
    "        # Filter labels by confidence threshold\n",
    "        prev_filtered = {label: conf for label, conf in prev_labels_to_confidence.items() if conf >= confidence_threshold}\n",
    "        filtered = {label: conf for label, conf in labels_to_confidence.items() if conf >= confidence_threshold}\n",
    "\n",
    "        common_labels = set(prev_filtered.keys()).intersection(filtered.keys())\n",
    "\n",
    "        if common_labels:\n",
    "            chosen_label, chosen_confidence = get_with_max_confidence(common_labels, prev_labels_to_confidence, labels_to_confidence)\n",
    "        else:\n",
    "            # Combine and sort all labels by confidence, regardless of threshold, if no common labels meet the threshold\n",
    "            all_labels_confidences = list(prev_labels_to_confidence.items()) + list(labels_to_confidence.items())\n",
    "            chosen_label, chosen_confidence = max(all_labels_confidences, key=lambda x: x[1])\n",
    "\n",
    "        chord_predictions.append((chosen_label, chosen_confidence))\n",
    "\n",
    "    return chord_predictions"
   ],
   "metadata": {
    "id": "ezVrdXhw-5vo"
   },
   "execution_count": 317,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Am', 1.0), ('Am', 1.0), ('Am', 1.0), ('F', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('G', 1.0), ('Em', 1.0), ('Em', 1.0), ('Em', 1.0), ('Am', 1.0), ('Em', 1.0), ('Em', 1.0), ('Em', 1.0), ('Em', 1.0), ('C', 1.0), ('Em', 1.0), ('C', 1.0), ('Em', 1.0), ('Em', 1.0), ('G', 1.0), ('G', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('C', 1.0), ('Em', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('Em', 1.0), ('C', 0.9999553561210632), ('F', 1.0), ('G', 1.0), ('G', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('F', 1.0), ('C', 1.0), ('C', 1.0), ('F', 1.0), ('F', 1.0), ('G', 1.0), ('G', 1.0), ('Am', 0.9999594688415527), ('C', 1.0), ('Am', 1.0), ('Am', 1.0), ('F', 1.0), ('F', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('C', 1.0), ('Am', 1.0), ('Am', 1.0), ('F', 1.0), ('F', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('Am', 1.0), ('Am', 1.0), ('Em', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('Em', 1.0), ('G', 1.0), ('G', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 0.8930985331535339), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('Em', 1.0), ('G', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('F', 1.0), ('F', 1.0), ('F', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('C', 1.0), ('Am', 1.0), ('Am', 1.0), ('F', 1.0), ('F', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('C', 1.0), ('Am', 1.0), ('F', 1.0), ('F', 1.0), ('F', 1.0), ('G', 1.0), ('Em', 1.0), ('C', 1.0), ('C', 1.0), ('C', 1.0), ('F', 1.0), ('F', 1.0), ('F', 1.0), ('G', 1.0), ('G', 1.0), ('Em', 1.0), ('C', 1.0), ('Am', 1.0), ('Am', 1.0), ('F', 1.0), ('F', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('Bb', 1.0), ('Am', 1.0), ('Am', 0.9999563694000244), ('F', 1.0), ('F', 1.0), ('G', 1.0), ('G', 1.0), ('C', 1.0), ('C', 1.0), ('G', 1.0), ('Em', 1.0), ('C', 0.9999477863311768), ('G', 1.0), ('G', 0.9999985694885254), ('Bb', 1.0), ('Bb', 0.9888486564159393), ('C', 1.0), ('Bb', 1.0), ('G', 1.0), ('Bb', 0.9999788999557495), ('Bb', 1.0), ('Bb', 0.7178656309843063), ('Bb', 1.0), ('Bb', 0.9999984502792358), ('Bb', 0.1964704841375351)]\n"
     ]
    }
   ],
   "source": [
    "chord_predictions = process_chord_predictions(top_labels_all, top_confidences_all)\n",
    "print(chord_predictions)"
   ],
   "metadata": {
    "id": "2rn0jPRNLONh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combine predictions into a chord sequence."
   ],
   "metadata": {
    "collapsed": false,
    "id": "-yVj4VV9LONi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "combined_predictions = []\n",
    "\n",
    "# Initialize the previous chord variable with None\n",
    "prev_chord = None\n",
    "\n",
    "# Iterate through each prediction\n",
    "for chord, confidence in chord_predictions:\n",
    "    # Check if the current chord is different from the previous chord\n",
    "    if chord != prev_chord:\n",
    "        # If it's different, append it to the combined list\n",
    "        combined_predictions.append(chord)\n",
    "        # Update the previous chord\n",
    "        prev_chord = chord"
   ],
   "metadata": {
    "id": "SX-5CaNXLONi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_chords(chord_predictions):\n",
    "    # Define a color scheme for each chord\n",
    "    chord_colors = {\n",
    "        \"Am\": \"#FFD700\",  # Gold\n",
    "        \"Bb\": \"#FF4500\",  # OrangeRed\n",
    "        \"Bdim\": \"#1E90FF\",  # DodgerBlue\n",
    "        \"C\": \"#32CD32\",  # LimeGreen\n",
    "        \"Dm\": \"#BA55D3\",  # MediumOrchid\n",
    "        \"Em\": \"#FF69B4\",  # HotPink\n",
    "        \"F\": \"#00CED1\",  # DarkTurquoise\n",
    "        \"G\": \"#FFA500\",  # Orange\n",
    "    }\n",
    "\n",
    "    # Start the HTML string for output\n",
    "    output = \"<div style='display: flex; flex-wrap: wrap;'>\"\n",
    "\n",
    "    # Counter to keep track of chords per line\n",
    "    chords_per_line = 0\n",
    "\n",
    "    for i, chord in enumerate(chord_predictions, start=1):\n",
    "        # Get the color for the current chord\n",
    "        color = chord_colors.get(chord, \"grey\")  # Default to grey if chord not found\n",
    "\n",
    "        # Create a div for the chord with the specific background color and white text for contrast\n",
    "        output += f\"<div style='color: white; margin: 5px; padding: 10px; background-color: {color}; width: 100px; text-align: center;'>{chord}</div>\"\n",
    "\n",
    "        # Increment the counter\n",
    "        chords_per_line += 1\n",
    "\n",
    "        # Check if we've reached 4 chords or the end of the list, then reset counter and add a line break\n",
    "        if chords_per_line == 4 or i == len(chord_predictions):\n",
    "            output += \"<div style='flex-basis: 100%; height: 0;'></div>\"  # This creates a line break in flexbox\n",
    "            chords_per_line = 0\n",
    "\n",
    "    # Close the HTML string\n",
    "    output += \"</div>\"\n",
    "\n",
    "    # Display the HTML in the Jupyter Notebook\n",
    "    display(HTML(output))\n"
   ],
   "metadata": {
    "id": "BqBOgC-wLONi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div style='display: flex; flex-wrap: wrap;'><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF4500; width: 100px; text-align: center;'>Bb</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFD700; width: 100px; text-align: center;'>Am</div><div style='color: white; margin: 5px; padding: 10px; background-color: #00CED1; width: 100px; text-align: center;'>F</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF69B4; width: 100px; text-align: center;'>Em</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF4500; width: 100px; text-align: center;'>Bb</div><div style='color: white; margin: 5px; padding: 10px; background-color: #32CD32; width: 100px; text-align: center;'>C</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF4500; width: 100px; text-align: center;'>Bb</div><div style='color: white; margin: 5px; padding: 10px; background-color: #FFA500; width: 100px; text-align: center;'>G</div><div style='flex-basis: 100%; height: 0;'></div><div style='color: white; margin: 5px; padding: 10px; background-color: #FF4500; width: 100px; text-align: center;'>Bb</div><div style='flex-basis: 100%; height: 0;'></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_chords(combined_predictions)"
   ],
   "metadata": {
    "id": "2epX51JILONi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "rPycLnN8LONi"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "V100",
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
